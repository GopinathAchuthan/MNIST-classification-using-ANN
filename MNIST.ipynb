{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UJjB-TedtWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import check_random_state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f-Z1LW63Jhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xor_input = np.array([[-1.2,-0.8],[-1.1,0.4],[0.57,-1.8],[1.23,0.92]])\n",
        "xor_output = np.array(['0','1','1','0'])\n",
        "X = xor_input\n",
        "y = xor_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JOZRmHhY9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = fetch_openml('mnist_784')\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iqUxhMmkVVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X / 255 #scaling input dataset\n",
        "digits = len(np.unique(y)) #10\n",
        "examples = y.shape[0] #70000\n",
        "y2 = y.reshape(1, examples)\n",
        "Y_new = np.eye(digits)[y2.astype('int32')]\n",
        "Y_new = Y_new.T.reshape(digits, examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1TY2ARvmEt0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "01defbec-a1fd-47d1-d7be-269c5ca2dc83"
      },
      "source": [
        "m = int(input(\"Enter the training data size [range (0, 70000)]: \"))\n",
        "print(\"Number of Training Data:\",m)\n",
        "m_test = X.shape[0] - m\n",
        "print(\"Number of Test Data:\",m_test)\n",
        "X_train, X_test = X[:m].T, X[m:].T\n",
        "Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
        "\n",
        "# shuffle the dataset\n",
        "shuffle_index = np.random.permutation(m)\n",
        "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the ratio for train test split [range (0, 1)]: 0.87\n",
            "Number of Training Data: 60900\n",
            "Number of Test Data: 9100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxuVqhoGnmcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e84ef212-7b78-4196-9283-a540b84803ea"
      },
      "source": [
        "#Checking the data\n",
        "i = 1 #i value can vary but it should be with range of m, that is number of training data\n",
        "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "print(\"Image Data\")\n",
        "plt.show()\n",
        "print(\"Label:\",np.argmax(Y_train[:,i]))"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Label: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCU42r9XqW-C",
        "colab_type": "text"
      },
      "source": [
        "Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDYwjR87owUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6228eee1-de94-442a-f571-b49eabef8200"
      },
      "source": [
        "def linear(z):\n",
        "  if z>0:\n",
        "    return 1\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "def sigmoid(z):\n",
        "  return 1. / (1. + np.exp(-z))\n",
        "\n",
        "def tanh(z):\n",
        "  return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
        "\n",
        "def ReLU(z):\n",
        "  return np.maximum(0,z)\n",
        "\n",
        "activation_function = linear #default option\n",
        "print(\"Choose activation function among the option given below:\")\n",
        "print(\"1.Linear function\")\n",
        "print(\"2.Sigmoid function\")\n",
        "print(\"3.Tanh function\")\n",
        "print(\"4.ReLU function\")\n",
        "\n",
        "opt = int(input(\"Enter in integer:\"))\n",
        "if opt == 1:\n",
        "  activation_function = linear\n",
        "elif opt == 2:\n",
        "  activation_function = sigmoid\n",
        "elif opt == 3:\n",
        "  activation_function = tanh\n",
        "elif opt == 4:\n",
        "  activation_function = ReLU"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose activation function among the option given below:\n",
            "1.Linear function\n",
            "2.Sigmoid function\n",
            "3.Tanh function\n",
            "4.ReLU function\n",
            "Enter in integer:2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsJeNzrtrBL7",
        "colab_type": "text"
      },
      "source": [
        "Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twPo0mhVq9KO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feed_forward(X, weights, bias):\n",
        "\n",
        "    forward = dict()\n",
        "    forward[1] = activation_function( np.matmul(weights[0], X) + bias[0] )\n",
        "\n",
        "    for i in range(2,len(weights)+1):\n",
        "      forward[i] = activation_function( np.matmul(weights[i-1], forward[i-1]) + bias[i-1] )\n",
        "\n",
        "    return forward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq1FEc2FrFjo",
        "colab_type": "text"
      },
      "source": [
        "Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLukRh-jrI3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_propagate(X, Y, weights, bias, forward):\n",
        "\n",
        "    grads_dW = dict()\n",
        "    grads_db = dict()\n",
        "    dZ = forward[len(forward)] - Y\n",
        "    grads_dW[len(forward)] = (1./m_batch) * np.matmul(dZ, forward[len(forward)-1].T)\n",
        "    grads_db[len(forward)] = (1./m_batch) * np.sum(dZ, axis=1, keepdims=True)\n",
        "\n",
        "    for i in range(len(forward)-1,1,-1):\n",
        "      dA = np.matmul(weights[i].T,dZ)\n",
        "      dZ = dA * forward[i] * (1 - forward[i])\n",
        "      grads_dW[i] = (1./m_batch) * np.matmul(dZ, forward[i-1].T)\n",
        "      grads_db[i] = (1./m_batch) * np.sum(dZ, axis=1, keepdims=True)\n",
        "\n",
        "    dA = np.matmul(weights[1].T, dZ)\n",
        "    dZ = dA * forward[1] * (1 - forward[1])\n",
        "    grads_dW[1] = (1./m_batch) * np.matmul(dZ, X.T)\n",
        "    grads_db[1] = (1./m_batch) * np.sum(dZ, axis=1, keepdims=True)\n",
        "    \n",
        "    return grads_dW, grads_db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bdht4NfPK4q",
        "colab_type": "text"
      },
      "source": [
        "Designing Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgPGVlkArUf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "72ffc7ba-ce55-476e-a289-76d4adaa34bf"
      },
      "source": [
        "np.random.seed(186)\n",
        "\n",
        "# hyperparameters\n",
        "number_of_hidden_layers = int(input(\"Enter number of hidden layer:\"))\n",
        "neurons_in_each_layer = list()\n",
        "neurons_in_each_layer.append(X_train.shape[0]) #input layer\n",
        "for i in range(number_of_hidden_layers):\n",
        "  neurons_in_each_layer.append(int(input(\"Enter number of neurons:\")))\n",
        "neurons_in_each_layer.append(digits)#output layer\n",
        "\n",
        "learning_rate = float(input(\"Enter learning rate:\"))\n",
        "beta = .9 #regulatization\n",
        "batch_size = int(input(\"Enter batch size:\"))\n",
        "batches = -(-m // batch_size)\n",
        "print(\"Number of batches:\",batches)"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter number of hidden layer:1\n",
            "Enter number of neurons:50\n",
            "Enter learning rate:0.3\n",
            "Enter batch size:500\n",
            "Number of batches: 122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ZGAib2jEdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = dict()\n",
        "bias = dict()\n",
        "for i in range(1,len(neurons_in_each_layer)):\n",
        "  weights[i-1] = np.random.randn(neurons_in_each_layer[i], neurons_in_each_layer[i-1]) * np.sqrt(1. / neurons_in_each_layer[i-1])\n",
        "  bias[i-1] = np.zeros((neurons_in_each_layer[i], 1)) * np.sqrt(1. / neurons_in_each_layer[i-1])\n",
        "\n",
        "V_dW = dict()\n",
        "V_db = dict()\n",
        "\n",
        "for i in range(len(weights)):\n",
        "  V_dW[i] = np.zeros(weights[i].shape)\n",
        "  V_db[i] = np.zeros(bias[i].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brrRnCuexFMz",
        "colab_type": "text"
      },
      "source": [
        "Mini Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6Hjhx0hxJk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d871644-2439-4e5f-90fb-c222fd136178"
      },
      "source": [
        "epoch = int(input(\"Enter epoch value:\"))"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter epoch value:1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIZtS2SvjX6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c5612a4-8911-487b-b648-a6653f8baf4b"
      },
      "source": [
        "acc_train_list = list()\n",
        "acc_test_list = list()\n",
        "for i in range(epoch): #convergence\n",
        "    #print(\"Epoch:\",i+1)\n",
        "    permutation = np.random.permutation(X_train.shape[1])\n",
        "    X_train_shuffled = X_train[:, permutation]\n",
        "    Y_train_shuffled = Y_train[:, permutation]\n",
        "\n",
        "    for j in range(batches):\n",
        "\n",
        "        begin = j * batch_size\n",
        "        end = min(begin + batch_size, X_train.shape[1] - 1)\n",
        "\n",
        "        X_shuf = X_train_shuffled[:, begin:end]\n",
        "        Y_shuf = Y_train_shuffled[:, begin:end]\n",
        "        m_batch = end - begin\n",
        "\n",
        "        forward = feed_forward(X_shuf, weights, bias)\n",
        "        grads_dW, grads_db = back_propagate(X_shuf, Y_shuf, weights, bias, forward)\n",
        "\n",
        "        for k in range(len(V_dW)):\n",
        "          V_dW[k] = (beta * V_dW[k] + (1. - beta) * grads_dW[k+1])\n",
        "          V_db[k] = (beta * V_db[k] + (1. - beta) * grads_db[k+1])\n",
        "\n",
        "        for k in range(len(weights)):\n",
        "          weights[k] = weights[k] - learning_rate * V_dW[k]\n",
        "          bias[k] = bias[k] - learning_rate * V_db[k]\n",
        "        \n",
        "    #Accuracy score of Training Data\n",
        "    forward = feed_forward(X_train, weights, bias)\n",
        "    acc_train = accuracy_score(np.argmax(forward[len(forward)], axis=0), np.argmax(Y_train, axis=0))\n",
        "    #Accuracy score of Test Data\n",
        "    forward = feed_forward(X_test, weights, bias)\n",
        "    acc_test = accuracy_score(np.argmax(forward[len(forward)], axis=0), np.argmax(Y_test, axis=0))\n",
        "    \n",
        "    print(\"Epoch {}: Accuracy score on Training Data = {},   Accuracy score on Test Data = {}\".format(i+1, acc_train, acc_test))\n",
        "    \n",
        "    acc_train_list.append(acc_train)\n",
        "    acc_test_list.append(acc_test)\n",
        "\n",
        "    if acc_train == 1.0: #convergence\n",
        "      break\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 483: Accuracy score on Training Data = 0.9955336617405582,   Accuracy score on Test Data = 0.9715384615384616\n",
            "Epoch 484: Accuracy score on Training Data = 0.995615763546798,   Accuracy score on Test Data = 0.9724175824175825\n",
            "Epoch 485: Accuracy score on Training Data = 0.995632183908046,   Accuracy score on Test Data = 0.9715384615384616\n",
            "Epoch 486: Accuracy score on Training Data = 0.9956486042692939,   Accuracy score on Test Data = 0.9721978021978022\n",
            "Epoch 487: Accuracy score on Training Data = 0.9956650246305419,   Accuracy score on Test Data = 0.9723076923076923\n",
            "Epoch 488: Accuracy score on Training Data = 0.9956650246305419,   Accuracy score on Test Data = 0.9717582417582418\n",
            "Epoch 489: Accuracy score on Training Data = 0.9955829228243022,   Accuracy score on Test Data = 0.9715384615384616\n",
            "Epoch 490: Accuracy score on Training Data = 0.9958456486042693,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 491: Accuracy score on Training Data = 0.9957307060755337,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 492: Accuracy score on Training Data = 0.9957142857142857,   Accuracy score on Test Data = 0.9715384615384616\n",
            "Epoch 493: Accuracy score on Training Data = 0.9957142857142857,   Accuracy score on Test Data = 0.9723076923076923\n",
            "Epoch 494: Accuracy score on Training Data = 0.9958292282430213,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 495: Accuracy score on Training Data = 0.9958128078817734,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 496: Accuracy score on Training Data = 0.9958620689655172,   Accuracy score on Test Data = 0.9721978021978022\n",
            "Epoch 497: Accuracy score on Training Data = 0.9959113300492611,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 498: Accuracy score on Training Data = 0.9959113300492611,   Accuracy score on Test Data = 0.9716483516483516\n",
            "Epoch 499: Accuracy score on Training Data = 0.9959113300492611,   Accuracy score on Test Data = 0.9721978021978022\n",
            "Epoch 500: Accuracy score on Training Data = 0.9958620689655172,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 501: Accuracy score on Training Data = 0.9959113300492611,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 502: Accuracy score on Training Data = 0.9958784893267651,   Accuracy score on Test Data = 0.9715384615384616\n",
            "Epoch 503: Accuracy score on Training Data = 0.9958949096880131,   Accuracy score on Test Data = 0.9720879120879121\n",
            "Epoch 504: Accuracy score on Training Data = 0.9959277504105091,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 505: Accuracy score on Training Data = 0.9959113300492611,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 506: Accuracy score on Training Data = 0.9960591133004926,   Accuracy score on Test Data = 0.9720879120879121\n",
            "Epoch 507: Accuracy score on Training Data = 0.9960919540229886,   Accuracy score on Test Data = 0.9716483516483516\n",
            "Epoch 508: Accuracy score on Training Data = 0.9960262725779967,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 509: Accuracy score on Training Data = 0.9959770114942529,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 510: Accuracy score on Training Data = 0.9961904761904762,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 511: Accuracy score on Training Data = 0.9961412151067324,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 512: Accuracy score on Training Data = 0.9961740558292282,   Accuracy score on Test Data = 0.9717582417582418\n",
            "Epoch 513: Accuracy score on Training Data = 0.99623973727422,   Accuracy score on Test Data = 0.9721978021978022\n",
            "Epoch 514: Accuracy score on Training Data = 0.99623973727422,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 515: Accuracy score on Training Data = 0.9961412151067324,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 516: Accuracy score on Training Data = 0.9961904761904762,   Accuracy score on Test Data = 0.9716483516483516\n",
            "Epoch 517: Accuracy score on Training Data = 0.9963218390804598,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 518: Accuracy score on Training Data = 0.9963218390804598,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 519: Accuracy score on Training Data = 0.9961576354679803,   Accuracy score on Test Data = 0.9720879120879121\n",
            "Epoch 520: Accuracy score on Training Data = 0.9963875205254515,   Accuracy score on Test Data = 0.9716483516483516\n",
            "Epoch 521: Accuracy score on Training Data = 0.9963054187192119,   Accuracy score on Test Data = 0.9724175824175825\n",
            "Epoch 522: Accuracy score on Training Data = 0.9963382594417077,   Accuracy score on Test Data = 0.9723076923076923\n",
            "Epoch 523: Accuracy score on Training Data = 0.9962889983579639,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 524: Accuracy score on Training Data = 0.9963875205254515,   Accuracy score on Test Data = 0.9720879120879121\n",
            "Epoch 525: Accuracy score on Training Data = 0.9963382594417077,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 526: Accuracy score on Training Data = 0.9963382594417077,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 527: Accuracy score on Training Data = 0.9963875205254515,   Accuracy score on Test Data = 0.9718681318681318\n",
            "Epoch 528: Accuracy score on Training Data = 0.9964367816091954,   Accuracy score on Test Data = 0.9717582417582418\n",
            "Epoch 529: Accuracy score on Training Data = 0.9964367816091954,   Accuracy score on Test Data = 0.971978021978022\n",
            "Epoch 530: Accuracy score on Training Data = 0.9965353037766831,   Accuracy score on Test Data = 0.9718681318681318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-312-204b0e3da7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_shuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mgrads_dW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_shuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_shuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_dW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-308-a8472ebd8a1e>\u001b[0m in \u001b[0;36mback_propagate\u001b[0;34m(X, Y, weights, bias, forward)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mgrads_dW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mgrads_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_voFNt0DLCm",
        "colab_type": "text"
      },
      "source": [
        "Plotting Accuracy Score VS Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbp9lRPZ02Ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(len(acc_train_list)),acc_train_list)\n",
        "plt.plot(range(len(acc_test_list)),acc_test_list)\n",
        "\n",
        "plt.suptitle('Accuracy VS Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.legend([\"Training Data\", \"Test Data\"])\n",
        "\n",
        "plt.xlim(0, len(acc_train_list)*1.05)\n",
        "plt.ylim(min(acc_test_list), max(acc_train_list)+0.05)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBEaJCrzCzuJ",
        "colab_type": "text"
      },
      "source": [
        "Classification Report on Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PhfBya2CyxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward = feed_forward(X_train, weights, bias)\n",
        "predictions = np.argmax(forward[len(forward)], axis=0)\n",
        "labels = np.argmax(Y_train, axis=0)\n",
        "\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M35wHTEx2eO",
        "colab_type": "text"
      },
      "source": [
        "Classification Report on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuXq4EiRjlnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward = feed_forward(X_test, weights, bias)\n",
        "predictions = np.argmax(forward[len(forward)], axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "\n",
        "print(classification_report(predictions, labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID_hHgJWR9EG",
        "colab_type": "text"
      },
      "source": [
        "Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOlFjcv5SBta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4bba68f7-5744-4316-8118-b87fdc0c8a09"
      },
      "source": [
        "train_samples = 60000\n",
        "\n",
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_samples, test_size=10000)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#Logistic Regression Model\n",
        "clf = LogisticRegression(C=50. / train_samples, penalty='l1', solver='saga', tol=0.1)\n",
        "clf.fit(X_train, y_train)\n",
        "sparsity = np.mean(clf.coef_ == 0) * 100\n",
        "print(\"Accuracy Score on Training Data:\",clf.score(X_train, y_train))\n",
        "\n",
        "print(\"Accuracy Score on Test Data:\",clf.score(X_test, y_test))"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score on Training Data: 0.8400666666666666\n",
            "Accuracy Score on Test Data: 0.837\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}